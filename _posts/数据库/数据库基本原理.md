## 实例与存储
数据库不仅仅拥有存储（Store），还应当有为外界提供数据服务的程序，这个程序对存储的操作细节进行封装，对外提供简单的服务，通常把它叫作实例（Instance），有了存储与实例的组合，才称为真正的数据库。
## 数据库基本原理
- 块与页：数据库通常不会以行为单位来加载数据，因为行的粒度大小不容易控制，也不利于调度管理。数据库通常对数据做物理大小的划分，例如以4KB、8KB、16KB等大小为基本单位来存储，单位的名称有的数据叫作块（Block），有的数据库称作页（Page）。通常每个块hui会存储多行数据，数据库为了记住每个块，通常会给每个块分配一个标识符（这个标识符不一定是唯一的，不过它可能与某些更高抽象层次的标识符组成一个唯一标识符，例如对象编号、表空间编号）。由于块内部存放多条数据，为了表示每条数据，块内部的每条数据通常都有自己的行号。在不同的应用中，可能会设置不同大小的块，希望它存储相对较多的数据，又便于数据库中细粒度的管理。

物理的磁盘并不会单独生成一个块，也没有“块”这个概念，“块”本身也是将文件系统中的某个数据范围抽象出来的逻辑概念，由于数据库对存储的输入/输出控制有自己规约好的一套体系，因此数据库实例程序可以识别出”块“。数据库有数据字典来记录数据库各种各样的信息，它们会记录下每个块在文件系统中的偏移量，相当于记住了它的位置，找到了偏移量就等价于找到了块的起始位置，再从这个起始位置开始读取等同于块大小的区域就成功地读取了这个块存放的内容。这种文件的操作方式类似于Java用随机读／写来访问文件。
- 多个连续的块。一个表要存储许多数据，随着数据的增加肯定不止一个块来存放，也就是需要很多这样块来存放数据，这些块存放的位置或许会在一定程度上影响性能。

通常存储设备的效率是最低的，数据库性能的巨大障碍之一就是磁盘存储，而磁盘存储效率低主要是低在IOPS上面，即每秒可以发生的I/O操作次数太低（不考虑固态硬盘），其实每次I/O操作从磁盘上读取连续的1KB或连续1MB左右的数据时间几乎是差不多。换句话说，慢的主要原因是一个硬盘只有一个磁头，对一块硬盘的I/O请求都会被串行化，每个I/O请求都需要通过摆头摆动进行磁道定位，再在磁道内通过磁盘旋转等待数据的开始位置，当数据开始位置找到后，便开始真正读取数据，读取速度是非常快的。根据上述理论，我们希望数据库每次读取的不仅仅是1KB，2KB、4KB的数据，很多时候我们希望读取到更多的数据，此时将多个块的数据连续放在一起组成一组数据，这样在理想情况下可以成倍提升存储设备的性能。

我们将多个块一起读的操作叫作顺序读，顺序读是相对随机读的，也就是每次读取的量会更大一些，但是在物理上并不存在每次读取100MB的数据，即使应用程序是这样的，物理上一会拆分成多个小的I/O来调度。

将多个块组成一个分组后，这个分组在一些数据库上叫做extends，它被认为在文件系统这个级别是连续存储的，理论上在磁盘上是相对连续的一块空间，但不绝对保证是这样的，就像一个大文件存放在磁盘上时，也会在磁盘碎片的空隙中寻找位置一样。换句话说，这种连续是逻辑上的，但是只要做好相对应的碎片管理，在很多时候认为它确实是连续的。

我们希望读写操作都是顺序的，不过在许多实际场景中往往不是这样的，由于内存空间的限制，数据库通常会以类似于LRU的算法来管理块，让某些访问多的块留在内存，或让访问少的块从内存中释放掉。如果一些连续的数据块加载后，这些连续块中的部分没有被访问，那么这部分块就可能会在LRU的调度下写回磁盘，这些连续加载的顺序块之间存在空隙，而当再次加载这样的块时，数据库通常不会再一次连续加载这些块，而是加载空隙中所没有加载的块，当连续块之中出现多个空隙时，通常需要发生多次I/O操作来读取这些空隙块，这样顺序读操作就变成了随机读，最坏的情况就是在一大堆连续块中空隙块与内存中的Cache的块交替出现。

有些时候数据库的分布不容易被确定，但是一些索引的顺序时可以被确定的，以为你索引本身是有序的，尤其是基于自动增长列这类索引，离这类数据最近的数据通常时访问最热的，那么被连续加载的概率时很高的，如果将它散列，此时可能会稀疏分布在许多块上面。

另外，连续读的粒度并非仅仅受到磁盘的控制，通常数据库也会有参数来控制连续读的块个数。

在实际的数据库中，还有更大的空间概念。例如某些数据库会用多个extends组成一个Segments，一个表对象可以划分到多个Segements中，这样来实现分区表独立管理。

## 修改表
某些数据库会事先在写入每个块时给它们预留少部分空间，也就是每个块都不会写满，以便于添加字段时可以用，但是着并不能确保永远够用（例如增加一个超大字段）。如果空间不够用，就会将一行数据的某个部分放在另一个块当中，这两个块可能此时相隔很远，在访问数据库时，以前只需要一次I/O就可以得到的数据，现在需要多次I/O才可以。

遇到这类问题，虽然可以通过压缩、整理等方式来处理，但这个过程由于需要移动相关的数据，因此需要消耗数据库的性能。因此，对线上数据库加字段需要谨慎操作。

某些开源数据库没有数据字段的概念，大多数描述信息都是在以表为单位的文件头部完成的，当表结构修改时，通常会创建一个新表，并将原表中所有数据全部拷贝到新表中，在拷贝的过程中为了保证数据的一致性，通常会发生“锁表”的情况。对于小表，这样的操作可能会十分chang kuai畅快，但对于达标这样的操作将会十分恐怖，外界可能长时间无法访问这个表。因此对于大数据的存储，通常会采用“分库分表”策略。

## 删除表
删除表操作对于使用者来讲很简单，但是对于数据库却可能需要作出一番复杂的处理，因为表中可能会有大量的数据需要清理，一些商业数据库还会考虑表被误删除需要恢复的问题。

删除表时清理数据不可能像delete操作那样逐条去删除，通常是基于数据库的体系结构去清理的。例如基于页、块去清理，如果数据库表与文件对应，那么清理数据时可直接删除文件。

删除表时，相应的表在内存中可能还有数据，也应该被清理。某些数据库在内存中基于表名称Hash分布数据，这样就可以通过表名称快速定位到该表在内存中的数据，清理动作应该会很快。某些开源数据库的存储方式并非这样，它在内存中可能是基于一种线性结构来存储，此时可能会有一些问题，即使在数据库中删除一个“空表”，也可能导致系统延迟很大。

为什么？所有的数据库都存在内存命中率的问题，如果内存命中自然就不用访问效率低百倍的磁盘，因此对于数据库来讲，我们通常会给它配置较大的内存来达到很高的命中率。不过，这意味着如果要找到一个表在内存中Cache的数据有可能需要扫描整个数据区域，在某些时候还不止扫描一次，例如MySQL的InnoDB Buffer若设置非常大，那么在连续删除表时就可能导数据库系统性能下降，即使删除整个空表也会导致系统的延迟飙高。

删除某些数据库中的表，为了防止误删除，会在默认的处理删除动作时，只是修改名字并将修改后的表名与原来的表名做一个简单的映射，同时也改变元数据的状态，在默认情况下对外不可见。但是它依然暂用磁盘空间，数据一点不少存在。这样的删除操作自然是瞬间完成的，如果发现删错表了，通过一个简单的语句就可以瞬间恢复。如果想要直接物理删除表或清理回收站，就需要数据库提供特定的操作语法来完成。

## 一个SQL的运行可能会经历的步骤
当一个SQL请求访问到数据库时，通常会经历SQL解析的过程，这个解析过程就是将SQL语句解析为数据库操作。换句话说，SQL是人类约定语法后看得懂的信息，因为人类学会了如何解析SQL语句，但是传达到机器后，机器也需要认识SQL语句，它需要解析SQL语句后才知道到底需要做什么。

一些数据库为了提高并发的访问，让数据库运行得更快，会将这个解析过程缓存起来，因为它认为这样的系统通常SQL语句复用的概率很高，当同样的SQL语句发送过来时，就会取出已经解析好的结果直接运行，通常将这个过程叫作“软解析”，或者说它是假的解析。假设如果某软解析程序是自己写的，想继续优化，也许软解析过程可能不仅仅会保存SQL语句的解析结果，也可能会保存关联的结构信息（在表结构发生改变以前都是有效的），还可能会保存一些执行计划（在表的数据量没有发生太大变化时执行计划也不会有太大的变化），甚至可能会缓存一些SQL返回的平均行数、平均执行时间，在高并发的系统中可能用来做一些智能调度的优化策略。

数据字典就是用于保存数据库的一些描述信息，通常也是以表的方式存储的。由于一个数据库本身的对象通常不会太多，而且它的更新速度肯定不会像更新数据那么频繁，所以通常将它加载到内存中提供访问。

数据库访问自身的元数据时通常是可以通过抽象层次相对较低的API来完成的，但也不排除某些数据库也是用SQL完成的。总地来说，前面讲到的数据字典加载并不是说还要去查询一次数据库后台。

确保表和属性都存在后，数据库就要开始计划如何读取表中的数据并对数据进行处理，单表操作时会考虑是否走索引，多表操作时会用JOIN的方式或UNION的方式，排序有排序方法，分组有分组策略，它们始终沿着一条路径在执行数据库，数据库在执行语句前会计算出这条执行路径。数据库根据某些参数计算出的执行顺序，就是大家经常提到的“执行计划”。

要得到一个良好的执行计划是复杂的，因为它需要参考SQL的JOIN方式、原有表的大小、索引的建立方法等来综合计算得到执行计划的结论。

对于小表、访问量低的表，无所谓执行计划；对于大表、访问量高的表，执行计划显得特别重要，所以为了让数据ku

