---
layout : post
title : Storm入门
date : 2016-10-11
author : walkerljl
categories : blog
tag : Storm
---

# 一.为什么使用Storm？
Apache Storm是一个免费并且开源的分布式实时计算系统。Storm让可靠的处理流数据变得简单，相对于Hadoop的批量计算，Storm提供实时计算功能。Storm比较简单，通过任何一种编程语言都能够使用Storm。

Storm可以用于许多场景：
- 实时分析
- 在线机器学习
- 持续计算
- 分布式RPC
- ETL

Storm处理速度非常快：每秒每个节点能处理超过百万级别数量的Tuple。可扩展、容错、保证你的数据一定会被执行，并且搭建和操作都比较容易。

Strom集成了之前使用到的数据库和队列技术。一个Storm topology消费流数据并使用多种复杂的方式处理流数据，并且会上报流数据在每个阶段的计算信息。
# 二.基本概念与设计思想

![](/assets/images/blog/storm/storm-001.png)

- Storm是对流Stream的抽象，流是一个不间断的无界的连续tuple。Storm在建模事件流时，把流中的事件抽象为tuple即元祖。
- Storm将流中元素抽象为Tuple，一个tuple就是一个值列表value list，list中的每个value都有一个name，并且该value可以是基本类型、字符类型、字节数组等，当然也可以是其它可序列化的类型。
- Storm认为每个stream都有一个stream源，也就是原始元祖的源头，所以它将这个源头称之为Spout。
- 有了源头即spout也就是有了stream，那么该如何处理stream内的tuple？将流的状态转换称为Bolt，bolt可以消费任意数量的输入流，只要将流方向导向该bolt，同时它也可以发送新的流给其它bolt使用，这样一来，只要打开特定的spout（管口）再将spout中流出的tuple导向特定的bolt，bolt对导入的流做处理后再导入其它bolt或者目的地。
- 以上处理过程称为Topology即拓扑。拓扑是storm中最高层次的一个抽象概念，它可以被提交到storm集群执行，一个拓扑就是一个流转换图，图中每个节点是一个spout或者bolt，图中的边表示bolt订阅了哪些流，当spout或者bolt发送元组到流时，它就发送元组到每个订阅了该流的bolt（这意味着不需要我们手工拉管道，只要预先订阅，spout就会将流发送到合适的bolt上）。
-拓扑的每个节点都要说明它发射出去的元组的字段的name，其它节点只需要订阅该name就可以接收处理。

# 三.集群结构

![](/assets/images/blog/storm/storm-002.png)
![](/assets/images/blog/storm/storm-003.png)

- Storm集群表面类似Hadoop集群。但在Hadoop上你运行的是“MapReduce jobs”，在Storm上运行的“topologies”。“Jobs”和“topologies”是不同的，一个关键不同是一个MapReduce的Job最终会结束，而一个topology永远处理消息（或直到你kill它）。
- Storm集群有两种节点：控制（master）节点和工作者节点（worker）。
- 控制节点运行一个称之为“Supervisor”的后台程序。Supervisor监听分配给它所在机器的工作，基于Nimbus分配给它的事情来决定启动或停止工作者进程。每个工作者进程执行一个topology的子集（也就是一个子拓扑结构）；一个运行的topology由许多跨多个机器的工作者进程组成。
- 一个Zookeeper集群负Nimbus和多Supervisor之间的所有协调工作（一个完整的拓扑可能被分为多个子拓扑并由多个Supervisor完成）。
- 此外，Nimbus后台程序和Supervisor后台程序都是快速失败和无状态的。所有状态维持在Zookeeper或本地磁盘。因此，当你kill -9纱条nimbus或者supervisor进程，然后重启，它们将回复状态并继续工作，就像什么也没发生一样。这种设计使storm及其文档。这种设计中Master并没有直接和worker通信，而是借助Zookeeper分离master和worker的依赖，将状态信息存放在zookeeper集群内快速恢复任何失败的一方。

# 四.重要概念
- worker
 Supervisor会监听分配给它那台机器的工作，根据需要启动、关闭工作进程，这个工作进程就是worker。每一个worker都会占用工作节点的一个端口，这个端口可以在storm.yarm中配置。一个topology可能会在一个或者多个工作进程里面执行，每个工作进程执行整个topology的一部分，所以一个运行的topology由运行在很多机器上的很多工作进程组成。
 - Task
 每一个Spout和Bolt会被当做很多task在整个集群里面执行。默认情况下每一个task对应到一个线程（Executor），这个线程用来执行task，而stream grouping则是定义怎么从一堆task发射tuple到另外一堆task。每台Supervisor运行着若干个Worker进程，每个worker进程运行着如若干个Executor线程，每个Executor线程运行着同一个component（Spout或Bolt）的一个或多个task。
 
![](/assets/images/blog/storm/storm-004.png)

- Config（配置）
Storm里面有一堆参数可以配置来调整nimbus、supervisor以及正在运行的topology的行为，一些配置是系统级别的，一些配置是topology级别的。所有默认值的配置的默认配置在default.xml里面的。你可以通过storm.xml在你的classpath路径来覆盖这些默认配置。并且你也可以在代码里面设置一些topology相关的额配置信息-使用StormSubmitter。这些配置的优先级是：default.xml < storm.xml < TOPOLOGY-SPECIFIC配置。
- Stream Grouping（消息分发策略）

![](/assets/images/blog/storm/storm-005.png)

- Shuffle Grouping

随机分组，随机派发stream里面的tuple，保证每个bolt接收到的tuple数目相同。

- FieldsGrouping

按字段分组，比如按userid来分组，具有同样userid的tuple会被分到相同的Bolts，而不同的userid则会被分配到不同的Bolts。

- All Grouping

广播发送，对于每一个tuple，所有的Bolts都会收到。

- Global Grouping
全局分组，这个tuple被分配到storm中的一个bolt的其中一个task。再具体一点就是分配给id值最低的那个task。

- NonGrouping

不分组，这个分组的意思是说stream不关心到底谁会收到它的tuple。目前这种分组和Shuffle grouping是一样的效果，有一点不同的是storm会把这个bolt放到这个bolt的订阅者同一个线程里面去执行。

- Direct Grouping

直接分组, 这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的taskid 
(OutputCollector.emit方法也会返回taskid)。

# 五.可靠性
1. worker进程挂掉 

storm会重新再启动一个worker 

2. supervisor进程挂掉 

不会影响之前已经提交的topology，只是后期不会再向这个节点分配任务了。 

3. nimbus进程挂掉 

不会影响之前已经提交的topology，只是后期不能再向集群提交topology了。 

4. ack/fail消息确认机制(确保一个tuple被完全处理) 

在spout中发射tuple的时候需要同时发送messageid，这样才相当于开启了消息确认机制 
如果你的topology里面的tuple比较多的话， 那么把acker的数量设置多一点,效率会高一点。 
通过config.setNumAckers(num)来设置一个topology里面的acker的数量，默认值是1。 
注意： acker用了特殊的算法，使得对于追踪每个spout tuple的状态所需要的内存量是恒定的（20 bytes) 
注意：如果一个tuple在指定的timeout(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS默认值为30秒)时间内没有被成功处理，那么这个tuple会被认为处理失败了。

# 六.入门程序

```java

package spout;

import java.io.File;
import java.io.IOException;
import java.util.Collection;
import java.util.List;
import java.util.Map;

import org.apache.commons.io.FileUtils;
import backtype.storm.spout.SpoutOutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichSpout;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Values;

public class WordReader extends BaseRichSpout{


    //SpoutOutputCollector 发射器，负责向外面发射数据
    //conf 配置信息
    //private static final long serialVersionUID = 2756293133996402960L;
    private String inputpath;
    private SpoutOutputCollector collector;
    //当一个task被初始化时会调用此open方法
    public void open(Map conf, TopologyContext context,
            SpoutOutputCollector collector) {
         inputpath = (String) conf.get("INPUTPATH");
         this.collector = collector;
    }
    //这个方法会被一直调用
    public void nextTuple() {

        Collection<File> listFiles = FileUtils.listFiles(new File(inputpath), new String[]{"txt"}, true);
        for (File file : listFiles) {
            try {
                List<String> readLines = FileUtils.readLines(file);
                for (String line : readLines) {
                    this.collector.emit(new Values(line));
                }
                FileUtils.moveFile(file, new File(file.getAbsolutePath()+System.currentTimeMillis()));
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
    //声明发射的字段
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("line"));
    }
}

package bolt;

import java.util.Map;
import backtype.storm.task.OutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;

public class WordSpliter extends BaseRichBolt{

    //private static final long serialVersionUID = -3411512160818196264L;


    OutputCollector collector;
    @Override
    public void prepare(Map stormConf, TopologyContext context,
            OutputCollector collector) {
        this.collector = collector;
    }

    //一直执行
    @Override
    public void execute(Tuple input) {
        String stringByField = input.getStringByField("line");
        String[] split = stringByField.split(" ");
        for (String word : split) {
            this.collector.emit(new Values(word));
        }
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("word"));
    }   
}

package bolt;

import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import backtype.storm.task.OutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichBolt;
import backtype.storm.tuple.Tuple;

public class WordCounter extends BaseRichBolt{

    /**
     * 
     */
    //private static final long serialVersionUID = -8840777246416063904L;

    OutputCollector collector;
    HashMap<String, Integer> hashmap = new HashMap<String, Integer>();
    @Override
    public void prepare(Map stormConf, TopologyContext context,
            OutputCollector collector) {
        this.collector = collector;
        //每三秒统计一次
        new Thread(new Runnable() {

            @Override
            public void run() {

                while(true){
                    System.out.println("=======================");
                    for (Entry<String, Integer> entry : hashmap.entrySet()) {
                        System.out.println(entry.getKey()+"====="+entry.getValue());
                    }
                    try {
                        Thread.sleep(3000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }).start();

    }

    @Override
    public void execute(Tuple input) {
        String word = input.getStringByField("word");
        Integer integer = hashmap.get(word);

        if(integer == null){
            hashmap.put(word, 1);
        }else {
            hashmap.put(word, integer+1);
        }


    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {

    }
}

package topolopy;

import spout.WordReader;
import backtype.storm.Config;
import backtype.storm.LocalCluster;
import backtype.storm.topology.TopologyBuilder;
import bolt.WordCounter;
import bolt.WordSpliter;

public class WordCountTopo {

    public static void main(String[] args) {

        TopologyBuilder topologyBuilder = new TopologyBuilder();
        topologyBuilder.setSpout("wordreader", new WordReader());
        topologyBuilder.setBolt("wordspliter", new WordSpliter()).shuffleGrouping("wordreader");
        topologyBuilder.setBolt("wordcounter", new WordCounter()).shuffleGrouping("wordspliter");

        Config config = new Config();
        config.put("INPUTPATH", "j:\\inputdir");
        LocalCluster localCluster = new LocalCluster();
        localCluster.submitTopology("wordcount", config, topologyBuilder.createTopology());
    }

}

```
# 参考资料
- <http://storm.apache.org/releases/2.0.0-SNAPSHOT/Concepts.html>
- <http://blog.csdn.net/anonymous_cx/article/details/51171874>




















